import streamlit as st
import requests
from bs4 import BeautifulSoup
import json
import time
import random
import math
from typing import Dict, List, Tuple, Set
import re
from urllib.parse import quote, urljoin
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed


class WebConceptScraper:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)

    def search_wikipedia(self, word: str, max_concepts: int = 10) -> List[str]:
        """Wikipediaæ¤œç´¢ã‹ã‚‰é–¢é€£æ¦‚å¿µã‚’å–å¾—"""
        concepts = []
        try:
            # Wikipediaæ¤œç´¢API
            search_url = f"https://ja.wikipedia.org/api/rest_v1/page/summary/{quote(word)}"
            response = self.session.get(search_url, timeout=5)

            if response.status_code == 200:
                data = response.json()
                extract = data.get('extract', '')

                # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åè©ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
                concepts.extend(self._extract_concepts_from_text(extract, max_concepts // 2))

            # Wikipediaæ¤œç´¢çµæœã‹ã‚‰é–¢é€£ãƒšãƒ¼ã‚¸ã‚’å–å¾—
            search_api_url = f"https://ja.wikipedia.org/w/api.php"
            params = {
                'action': 'query',
                'format': 'json',
                'list': 'search',
                'srsearch': word,
                'srlimit': 5
            }

            response = self.session.get(search_api_url, params=params, timeout=5)
            if response.status_code == 200:
                data = response.json()
                search_results = data.get('query', {}).get('search', [])

                for result in search_results[:3]:
                    title = result.get('title', '')
                    snippet = result.get('snippet', '')
                    concepts.extend(self._extract_concepts_from_text(f"{title} {snippet}", 3))

        except Exception as e:
            st.warning(f"Wikipediaæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return list(set(concepts))[:max_concepts]

    def search_weblio(self, word: str, max_concepts: int = 8) -> List[str]:
        """Weblioè¾æ›¸ã‹ã‚‰é–¢é€£æ¦‚å¿µã‚’å–å¾—"""
        concepts = []
        try:
            url = f"https://www.weblio.jp/content/{quote(word)}"
            response = self.session.get(url, timeout=5)

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')

                # æ„å‘³ã‚„èª¬æ˜æ–‡ã‹ã‚‰æ¦‚å¿µã‚’æŠ½å‡º
                content_divs = soup.find_all('div', class_=['kiji', 'NetDicBody'])
                for div in content_divs[:2]:
                    text = div.get_text()
                    concepts.extend(self._extract_concepts_from_text(text, max_concepts // 2))

        except Exception as e:
            st.warning(f"Weblioæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return list(set(concepts))[:max_concepts]

    def search_google_related(self, word: str, max_concepts: int = 8) -> List[str]:
        """Googleæ¤œç´¢ã®é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        # å®Ÿéš›ã®Googleæ¤œç´¢APIã¯æœ‰æ–™ã®ãŸã‚ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        related_patterns = {
            "æŠ€è¡“": ["AI", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "ãƒ‡ã‚¸ã‚¿ãƒ«", "è‡ªå‹•åŒ–", "åŠ¹ç‡", "æœªæ¥", "ãƒ‡ãƒ¼ã‚¿"],
            "è‡ªç„¶": ["ç’°å¢ƒ", "ç”Ÿæ…‹ç³»", "å‹•ç‰©", "æ¤ç‰©", "æ°—å€™", "ä¿è­·", "å¾ªç’°", "å¤šæ§˜æ€§"],
            "é£Ÿã¹ç‰©": ["æ „é¤Š", "å¥åº·", "æ–™ç†", "æ–‡åŒ–", "å‘³", "é£Ÿæ", "ãƒ¬ã‚·ãƒ”", "é£Ÿäº‹"],
            "éŸ³æ¥½": ["ãƒ¡ãƒ­ãƒ‡ã‚£ãƒ¼", "ãƒªã‚ºãƒ ", "æ¥½å™¨", "æ„Ÿæƒ…", "èŠ¸è¡“", "è¡¨ç¾", "æ–‡åŒ–", "å‰µä½œ"],
            "ã‚¹ãƒãƒ¼ãƒ„": ["å¥åº·", "ä½“åŠ›", "ç«¶æŠ€", "ãƒãƒ¼ãƒ ", "ç·´ç¿’", "æŠ€è¡“", "ç²¾ç¥", "æˆé•·"],
            "å­¦ç¿’": ["çŸ¥è­˜", "ç†è§£", "è¨˜æ†¶", "æˆé•·", "ç™ºè¦‹", "å¥½å¥‡å¿ƒ", "åŠªåŠ›", "é”æˆ"],
        }

        # éƒ¨åˆ†ä¸€è‡´ã§é–¢é€£æ¦‚å¿µã‚’æ¤œç´¢
        concepts = []
        for key, values in related_patterns.items():
            if word in key or key in word:
                concepts.extend(values)

        # ãƒ©ãƒ³ãƒ€ãƒ ã«è¿½åŠ ã®æ¦‚å¿µã‚’ç”Ÿæˆ
        if len(concepts) < max_concepts:
            additional = ["å‰µé€ ", "ç™ºæƒ³", "ã‚¢ã‚¤ãƒ‡ã‚¢", "é©æ–°", "å¤‰åŒ–", "æˆé•·", "ç™ºå±•", "é€²æ­©"]
            concepts.extend(random.sample(additional, min(max_concepts - len(concepts), len(additional))))

        return concepts[:max_concepts]

    def _extract_concepts_from_text(self, text: str, max_concepts: int = 5) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ¦‚å¿µã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if not text:
            return []

        # HTMLã‚¿ã‚°ã‚’é™¤å»
        text = re.sub(r'<[^>]+>', '', text)

        # æ—¥æœ¬èªã®åè©ã£ã½ã„å˜èªã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        # ã‚«ã‚¿ã‚«ãƒŠã€ã²ã‚‰ãŒãªã€æ¼¢å­—ã®çµ„ã¿åˆã‚ã›
        patterns = [
            r'[ã‚¡-ãƒ¶ãƒ¼]{2,8}',  # ã‚«ã‚¿ã‚«ãƒŠ
            r'[ä¸€-é¾¯]{2,6}',  # æ¼¢å­—
            r'[ã-ã‚–]{2,6}',  # ã²ã‚‰ãŒãª
        ]

        concepts = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            concepts.extend(matches)

        # ä¸è¦ãªå˜èªã‚’é™¤å¤–
        exclude_words = {'ã§ã™', 'ã¾ã™', 'ã§ã‚ã‚‹', 'ã¨ã—ã¦', 'ã«ã¤ã„ã¦', 'ã«ã‚ˆã‚Š', 'ã«ã‚ˆã£ã¦', 'ã‹ã‚‰', 'ã¾ã§', 'ãªã©',
                         'ã“ã¨', 'ã‚‚ã®', 'ãŸã‚', 'ã¨ã“ã‚', 'ã¨ã', 'ã“ã“', 'ãã“', 'ã‚ãã“', 'ã“ã‚Œ', 'ãã‚Œ', 'ã‚ã‚Œ'}
        concepts = [c for c in concepts if c not in exclude_words and len(c) >= 2]

        return list(set(concepts))[:max_concepts]


class ConceptVisualizer:
    @staticmethod
    def calculate_positions(center_x: float, center_y: float, num_items: int, radius: float = 120) -> List[
        Tuple[float, float]]:
        """ä¸­å¿ƒç‚¹ã®å‘¨ã‚Šã«æ¦‚å¿µã‚’é…ç½®ã™ã‚‹åº§æ¨™ã‚’è¨ˆç®—"""
        if num_items == 0:
            return []

        positions = []
        for i in range(num_items):
            angle = (2 * math.pi * i) / num_items
            x = center_x + radius * math.cos(angle)
            y = center_y + radius * math.sin(angle)
            positions.append((x, y))
        return positions

    @staticmethod
    def create_concept_map(center_word: str, concepts: Dict[str, List[str]]) -> str:
        """å‹•çš„æ¦‚å¿µãƒãƒƒãƒ—ã‚’ä½œæˆ"""
        if not center_word or not concepts:
            return '<div style="text-align: center; padding: 50px;">æ¦‚å¿µã‚’æ¤œç´¢ä¸­...</div>'

        width, height = 800, 600
        center_x, center_y = width // 2, height // 2

        svg_content = f'''
        <div style="display: flex; justify-content: center;">
            <svg width="{width}" height="{height}" style="border: 1px solid #ddd; background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%); border-radius: 12px;">
                <!-- ä¸­å¿ƒã®å˜èª -->
                <circle cx="{center_x}" cy="{center_y}" r="40" fill="#2E7D32" stroke="#1B5E20" stroke-width="3"/>
                <text x="{center_x}" y="{center_y + 5}" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">{center_word}</text>
        '''

        colors = ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7", "#DDA0DD", "#98D8C8", "#F7DC6F"]
        source_colors = {"Wikipedia": "#FF6B6B", "Weblio": "#4ECDC4", "é–¢é€£æ¤œç´¢": "#45B7D1"}

        radius_offset = 0
        for source, concept_list in concepts.items():
            if not concept_list:
                continue

            source_radius = 150 + radius_offset
            positions = ConceptVisualizer.calculate_positions(center_x, center_y, len(concept_list), source_radius)
            color = source_colors.get(source, colors[0])

            for i, (concept, (x, y)) in enumerate(zip(concept_list, positions)):
                # ç·šã‚’æç”»
                svg_content += f'<line x1="{center_x}" y1="{center_y}" x2="{x}" y2="{y}" stroke="#ccc" stroke-width="2" stroke-dasharray="5,5" opacity="0.7"/>'

                # æ¦‚å¿µã®å††
                svg_content += f'<circle cx="{x}" cy="{y}" r="25" fill="{color}" stroke="white" stroke-width="2" opacity="0.9"/>'

                # æ¦‚å¿µã®ãƒ†ã‚­ã‚¹ãƒˆ
                display_text = concept if len(concept) <= 6 else concept[:5] + "..."
                svg_content += f'<text x="{x}" y="{y + 3}" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" font-weight="bold" fill="white">{display_text}</text>'

            radius_offset += 80

        # å‡¡ä¾‹ã‚’è¿½åŠ 
        legend_y = 30
        for i, (source, color) in enumerate(source_colors.items()):
            legend_x = 30 + i * 120
            svg_content += f'<circle cx="{legend_x}" cy="{legend_y}" r="8" fill="{color}"/>'
            svg_content += f'<text x="{legend_x + 15}" y="{legend_y + 4}" font-family="Arial, sans-serif" font-size="12" fill="#333">{source}</text>'

        svg_content += '</svg></div>'
        return svg_content


def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    if 'current_word' not in st.session_state:
        st.session_state.current_word = None
    if 'concepts' not in st.session_state:
        st.session_state.concepts = {}
    if 'search_history' not in st.session_state:
        st.session_state.search_history = []
    if 'concept_dictionary' not in st.session_state:
        st.session_state.concept_dictionary = {}


def search_concepts_parallel(scraper: WebConceptScraper, word: str) -> Dict[str, List[str]]:
    """ä¸¦åˆ—ã§è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰æ¦‚å¿µã‚’æ¤œç´¢"""
    concepts = {}

    with ThreadPoolExecutor(max_workers=3) as executor:
        # å„æ¤œç´¢ã‚’ä¸¦åˆ—å®Ÿè¡Œ
        future_to_source = {
            executor.submit(scraper.search_wikipedia, word): "Wikipedia",
            executor.submit(scraper.search_weblio, word): "Weblio",
            executor.submit(scraper.search_google_related, word): "é–¢é€£æ¤œç´¢"
        }

        for future in as_completed(future_to_source):
            source = future_to_source[future]
            try:
                result = future.result(timeout=10)
                concepts[source] = result
            except Exception as e:
                st.warning(f"{source}ã®æ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                concepts[source] = []

    return concepts


def save_concepts_to_dictionary(word: str, concepts: Dict[str, List[str]]):
    """æ¤œç´¢ã—ãŸæ¦‚å¿µã‚’è¾æ›¸ã«ä¿å­˜"""
    all_concepts = []
    for concept_list in concepts.values():
        all_concepts.extend(concept_list)

    # é‡è¤‡ã‚’é™¤å»
    unique_concepts = list(set(all_concepts))

    if unique_concepts:
        st.session_state.concept_dictionary[word] = unique_concepts


def export_dictionary():
    """æ¦‚å¿µè¾æ›¸ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    if st.session_state.concept_dictionary:
        return json.dumps(st.session_state.concept_dictionary, ensure_ascii=False, indent=2)
    return "{}"


def main():
    st.set_page_config(
        page_title="å‹•çš„æ¦‚å¿µç™ºè¦‹ã‚¢ãƒ—ãƒª",
        page_icon="ğŸ”",
        layout="wide"
    )

    initialize_session_state()

    st.title("ğŸ” å‹•çš„æ¦‚å¿µç™ºè¦‹ã‚¢ãƒ—ãƒª")
    st.markdown("**å˜èªã‚’å…¥åŠ›ã™ã‚‹ã¨ã€Webã‹ã‚‰é–¢é€£æ¦‚å¿µã‚’è‡ªå‹•åé›†ã—ã¦ç™ºæƒ³ã‚’åºƒã’ã¾ã™**")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        search_sources = st.multiselect(
            "æ¤œç´¢ã‚½ãƒ¼ã‚¹",
            ["Wikipedia", "Weblio", "é–¢é€£æ¤œç´¢"],
            default=["Wikipedia", "Weblio", "é–¢é€£æ¤œç´¢"]
        )

        max_concepts_per_source = st.slider("ã‚½ãƒ¼ã‚¹ã‚ãŸã‚Šã®æœ€å¤§æ¦‚å¿µæ•°", 3, 15, 8)

        st.header("ğŸ“š æ§‹ç¯‰æ¸ˆã¿è¾æ›¸")
        if st.session_state.concept_dictionary:
            st.write(f"ç™»éŒ²æ¸ˆã¿å˜èª: {len(st.session_state.concept_dictionary)}")

            # è¾æ›¸ã®å†…å®¹ã‚’è¡¨ç¤º
            with st.expander("è¾æ›¸ã®å†…å®¹"):
                for word, concepts in list(st.session_state.concept_dictionary.items())[:5]:
                    st.write(f"**{word}**: {', '.join(concepts[:5])}...")

            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
            if st.button("ğŸ“¥ è¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                dictionary_json = export_dictionary()
                st.download_button(
                    label="ğŸ’¾ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=dictionary_json,
                    file_name="concept_dictionary.json",
                    mime="application/json"
                )
        else:
            st.info("ã¾ã æ¦‚å¿µãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        # æ¤œç´¢å±¥æ­´
        st.header("ğŸ“œ æ¤œç´¢å±¥æ­´")
        if st.session_state.search_history:
            for i, word in enumerate(reversed(st.session_state.search_history[-5:])):
                if st.button(f"ğŸ”„ {word}", key=f"history_{i}"):
                    st.session_state.current_word = word
                    if word in st.session_state.concept_dictionary:
                        # æ—¢å­˜ã®æ¦‚å¿µã‚’è¡¨ç¤º
                        concepts = st.session_state.concept_dictionary[word]
                        st.session_state.concepts = {"ä¿å­˜æ¸ˆã¿": concepts}
                    st.rerun()

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    col1, col2 = st.columns([1, 2])

    with col1:
        st.header("ğŸ“ æ¦‚å¿µæ¤œç´¢")

        # æ¤œç´¢å…¥åŠ›
        search_word = st.text_input(
            "æ¤œç´¢ã—ãŸã„å˜èªã‚’å…¥åŠ›:",
            placeholder="ä¾‹: äººå·¥çŸ¥èƒ½ã€ç’°å¢ƒå•é¡Œã€éŸ³æ¥½ã€æ–™ç†..."
        )

        # æ¤œç´¢ãƒœã‚¿ãƒ³
        if st.button("ğŸ” æ¦‚å¿µã‚’æ¤œç´¢", type="primary"):
            if search_word and search_word.strip():
                word = search_word.strip()

                # æ¤œç´¢ä¸­ã®è¡¨ç¤º
                with st.spinner(f"ã€Œ{word}ã€ã®é–¢é€£æ¦‚å¿µã‚’æ¤œç´¢ä¸­..."):
                    scraper = WebConceptScraper()

                    # ä¸¦åˆ—æ¤œç´¢å®Ÿè¡Œ
                    concepts = search_concepts_parallel(scraper, word)

                    # é¸æŠã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
                    filtered_concepts = {k: v for k, v in concepts.items() if k in search_sources}

                    if any(filtered_concepts.values()):
                        st.session_state.current_word = word
                        st.session_state.concepts = filtered_concepts

                        # è¾æ›¸ã«ä¿å­˜
                        save_concepts_to_dictionary(word, filtered_concepts)

                        # å±¥æ­´ã«è¿½åŠ 
                        if word not in st.session_state.search_history:
                            st.session_state.search_history.append(word)

                        st.success(f"ã€Œ{word}ã€ã®æ¦‚å¿µã‚’æ¤œç´¢ã—ã¾ã—ãŸï¼")
                    else:
                        st.warning("é–¢é€£æ¦‚å¿µãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.error("æ¤œç´¢ã™ã‚‹å˜èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

        # ç¾åœ¨ã®æ¤œç´¢çµæœ
        if st.session_state.current_word and st.session_state.concepts:
            st.subheader(f"ğŸ¯ ã€Œ{st.session_state.current_word}ã€ã®é–¢é€£æ¦‚å¿µ")

            for source, concept_list in st.session_state.concepts.items():
                if concept_list:
                    st.write(f"**{source}** ({len(concept_list)}å€‹):")
                    for i, concept in enumerate(concept_list, 1):
                        if st.button(f"{i}. {concept}", key=f"concept_{source}_{i}"):
                            # ã‚¯ãƒªãƒƒã‚¯ã—ãŸæ¦‚å¿µã§æ–°ã—ã„æ¤œç´¢
                            st.session_state.current_word = concept
                            # æ—¢å­˜ã®æ¦‚å¿µãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                            if concept in st.session_state.concept_dictionary:
                                existing_concepts = st.session_state.concept_dictionary[concept]
                                st.session_state.concepts = {"ä¿å­˜æ¸ˆã¿": existing_concepts}
                            else:
                                st.session_state.concepts = {}
                            st.rerun()

        # ã‚¯ãƒªã‚¢æ©Ÿèƒ½
        if st.button("ğŸ—‘ï¸ çµæœã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.current_word = None
            st.session_state.concepts = {}
            st.success("æ¤œç´¢çµæœã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

    with col2:
        st.header("ğŸ¨ æ¦‚å¿µãƒãƒƒãƒ—")

        if st.session_state.current_word and st.session_state.concepts:
            # æ¦‚å¿µãƒãƒƒãƒ—ã‚’è¡¨ç¤º
            concept_map = ConceptVisualizer.create_concept_map(
                st.session_state.current_word,
                st.session_state.concepts
            )
            st.markdown(concept_map, unsafe_allow_html=True)

            # çµ±è¨ˆæƒ…å ±
            st.subheader("ğŸ“Š æ¤œç´¢çµ±è¨ˆ")
            total_concepts = sum(len(concepts) for concepts in st.session_state.concepts.values())

            col2_1, col2_2, col2_3 = st.columns(3)
            with col2_1:
                st.metric("ä¸­å¿ƒæ¦‚å¿µ", st.session_state.current_word)
            with col2_2:
                st.metric("ç·æ¦‚å¿µæ•°", total_concepts)
            with col2_3:
                st.metric("æ¤œç´¢ã‚½ãƒ¼ã‚¹æ•°", len([s for s in st.session_state.concepts.values() if s]))

            # æ¦‚å¿µã®è©³ç´°è¡¨ç¤º
            with st.expander("ğŸ“‹ æ¦‚å¿µã®è©³ç´°"):
                for source, concept_list in st.session_state.concepts.items():
                    if concept_list:
                        st.write(f"**{source}**: {', '.join(concept_list)}")
        else:
            st.info("å·¦å´ã§å˜èªã‚’æ¤œç´¢ã™ã‚‹ã¨ã€ã“ã“ã«æ¦‚å¿µãƒãƒƒãƒ—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

            # ãƒ‡ãƒ¢ç”¨ã®èª¬æ˜
            st.subheader("ğŸŒŸ ã‚¢ãƒ—ãƒªã®ç‰¹å¾´")
            st.markdown("""
            - **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢**: Webã‹ã‚‰æœ€æ–°ã®é–¢é€£æ¦‚å¿µã‚’å–å¾—
            - **è¤‡æ•°ã‚½ãƒ¼ã‚¹**: Wikipediaã€Weblioã€é–¢é€£æ¤œç´¢ã‹ã‚‰æƒ…å ±åé›†
            - **è¦–è¦šçš„è¡¨ç¾**: ç¾ã—ã„æ¦‚å¿µãƒãƒƒãƒ—ã§é–¢é€£æ€§ã‚’è¡¨ç¤º
            - **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–**: æ¦‚å¿µã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦é€£æƒ³ã‚’åºƒã’ã‚‹
            - **è¾æ›¸æ§‹ç¯‰**: æ¤œç´¢ã—ãŸæ¦‚å¿µã‚’è‡ªå‹•çš„ã«è¾æ›¸ã«è“„ç©
            - **å±¥æ­´æ©Ÿèƒ½**: éå»ã®æ¤œç´¢ã‚’ç°¡å˜ã«å†åˆ©ç”¨
            """)

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("ğŸ” **å‹•çš„æ¦‚å¿µç™ºè¦‹**: Webã‹ã‚‰æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã—ã¦ã€ã‚ãªãŸã®ç™ºæƒ³ã‚’ç„¡é™ã«åºƒã’ã¾ã™")


if __name__ == "__main__":
    main()
